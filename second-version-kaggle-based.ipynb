{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["ut6ZVSP6Gb4F","peZaBR-_nhCl"],"include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8564242,"sourceType":"datasetVersion","datasetId":5119916}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# The code is modified to work properly on the dataset directories on kaggle\n- Please run it (with mirror or without, its your call), currently I have major internet problems regarding an stable connection to the Kaggle.\n- I estimate it to take around ~2:30-3 Hours on single P100 to run fully (2 Epochs/ Per Minute) without Mirror.\n- I have modified the number of epochs and also the dropout rate to make the training a bit more time-efficient with minimum knowledge base loss during training.\n- Also cleaned the code in general (Removed redundent functions for Generators and Visualizations).\n- Please make sure to commit your possible changed version as a new version to the repo.\n\n@Good Luck","metadata":{}},{"cell_type":"markdown","source":"# Requirements","metadata":{"id":"by1o5v5UDBtj"}},{"cell_type":"code","source":"import cv2\nimport shutil\nimport random\nimport zipfile\nimport warnings\nimport numpy as np\n# %load_ext cudf.pandas\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications.resnet import ResNet50\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom tensorflow.keras.callbacks import CSVLogger\n\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"TWChDwKVCjJ7","outputId":"c778b8b1-4ec2-4e72-e0ad-d304d40f225e","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"benigns = len(os.listdir(\"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/benign\"))\nmelignant = len(os.listdir(\"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/malignant\"))\nprint(f\"Number of benign Samples: {benigns}\\nNumber of malignant Samples: {melignant}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASydytmeE3lj","outputId":"c7f5e8dc-7f75-4650-ef71-345b764d446a","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n> Removing random samples from the majority class\n\n","metadata":{"id":"yIo3klWahm44"}},{"cell_type":"code","source":"# Balance the dataset by removing excess samples from the majority class\nfrom random import sample\nmin_path = \"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/malignant\"\nmaj_path = \"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/benign\"\naddress = [image for image in os.listdir(maj_path)]\ncut = len(os.listdir(min_path))\ncut_list = sample(address, cut)\nfor index in tqdm(os.listdir(maj_path)):\n    if index not in cut_list:\n        os.remove(os.path.join(maj_path, index))\n\n# Verify the number of samples\nbenigns = len(os.listdir(\"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/benign\"))\nmelignant = len(os.listdir(\"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/malignant\"))\nprint(f\"\\nNumber of benign Samples: {benigns}\\nNumber of malignant Samples: {melignant}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WERv5Wrohmmf","outputId":"645d09b5-1a66-4f09-d701-db05ebb0270f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to divide test set\ndef divide_test_set(temp_path, cut_percentage):\n    rel_image_paths = [os.path.join(temp_path, i) for i in os.listdir(temp_path)]\n    cut_set = random.sample(rel_image_paths, int(cut_percentage * len(os.listdir(temp_path))))\n    return cut_set","metadata":{"id":"GdxvWj18klvy","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n> Remmeber to Rename \"Melanoma-b584m584\" folder to \"train\" before running the next cells\n","metadata":{"id":"B8KaTj5DrCTR"}},{"cell_type":"code","source":"# Here since the path to dataset is read-only we need to copy them to another Dir\nnew_path = '/kaggle/working/train'\nos.makedirs(new_path, exist_ok=True)\nshutil.copytree('/kaggle/input/skin-canser-b584m584/Melanoma-b584m584', new_path, dirs_exist_ok=True)\n# Just to Verify\nprint(os.listdir(new_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Divide the dataset into training and test sets\ninput_path = \"/kaggle/working/train/benign\"\nbenign_test_set = divide_test_set(input_path, 0.20)\ninput_path = \"/kaggle/working/train/malignant\"\nmalignant_test_set = divide_test_set(input_path, 0.20)","metadata":{"id":"FA7qjcoimOXj","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"benign_test_path = \"/kaggle/working/test/benign\"\nos.makedirs(benign_test_path, exist_ok=True)\nfor index in tqdm(benign_test_set):\n    shutil.move(index, benign_test_path)\n\nprint(len(os.listdir(benign_test_path)))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rllSdWZsqXiD","outputId":"2de0ea9e-b993-4511-bede-bca99949df3d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"malignant_test_path = \"/kaggle/working/test/malignant\"\nos.makedirs(malignant_test_path, exist_ok=True)\nfor index in tqdm(malignant_test_set):\n    shutil.move(index, malignant_test_path)\n\nprint(len(os.listdir(malignant_test_path)))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PNzniSzZtw-y","outputId":"af21fb2f-b01b-4362-859c-8e151010543c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n> Load and shuffle the data\n\n","metadata":{"id":"Z5GIh0e0PgI5"}},{"cell_type":"code","source":"# Data generator for training, validation and testing\ndef create_generator(DIR):\n    datagen = ImageDataGenerator(rescale=1/255)\n    generator = datagen.flow_from_directory(directory=DIR,\n                                            batch_size=batch_size,\n                                            class_mode='binary',\n                                            target_size=(224, 224))\n    return generator","metadata":{"id":"Xteh2dlNMGjK","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to shuffle and split data\ndef shuffle_and_split_data(src_dir, dest_dir, split_percent):\n    image_filenames = os.listdir(src_dir)\n    num_images = len(image_filenames)\n    random.shuffle(image_filenames)\n    num_images_to_move = int(num_images * split_percent)\n    for i in tqdm(range(num_images_to_move)):\n        src_path = os.path.join(src_dir, image_filenames[i])\n        dest_path = os.path.join(dest_dir, image_filenames[i])\n        shutil.move(src_path, dest_path)","metadata":{"id":"5CHaxUPmM8mb","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create train and validation directories\ntrain_benign_dir = \"/kaggle/working/train/benign\"\ntrain_malignant_dir = \"/kaggle/working/train/malignant\"\nvalidation_dir = \"/kaggle/working/validation\"\nos.makedirs(validation_dir, exist_ok=True)\nvalidation_benign_dir = os.path.join(validation_dir, \"benign\")\nvalidation_malignant_dir = os.path.join(validation_dir, \"malignant\")\nos.makedirs(validation_benign_dir, exist_ok=True)\nos.makedirs(validation_malignant_dir, exist_ok=True)","metadata":{"id":"5Nz4dmIkM9Wh","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_percent = 0.20\nshuffle_and_split_data(train_benign_dir, validation_benign_dir, split_percent)\nshuffle_and_split_data(train_malignant_dir, validation_malignant_dir, split_percent)\n\nprint(\"\\nData shuffling and splitting completed.\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g7kU72x_M9Zw","outputId":"8d596e21-717b-4c17-8a92-3d21ce9809ed","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verification\nva = len(os.listdir(\"/kaggle/working/validation/benign\"))\ntr = len(os.listdir(\"/kaggle/working/train/benign\"))\nprint(f\"\\nNumber of benign train Samples: {tr}\\nNumber of benign validation Samples: {va}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u-GuYMRSM9co","outputId":"5c1b77d3-526e-426b-f832-2af5abb7b921","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Verification\nva_ = len(os.listdir(\"/kaggle/working/validation/malignant\"))\ntr_ = len(os.listdir(\"/kaggle/working/train/malignant\"))\nprint(f\"\\nNumber of malignant train Samples: {tr_}\\nNumber of malignant validation Samples: {va_}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9asI2TqgQBY4","outputId":"0b6693c4-285b-4558-fb64-800af9e56b62","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# (it should be ~935)\nva+va_+tr_+tr","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XUwhkKfXQNle","outputId":"0571da86-0ce4-4e60-f51b-62dc73e4ab68","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training parameters\nbatch_size = 4\nEPOCHS = 40","metadata":{"id":"3jRWbnNYLIFB","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Train_Dir = '/kaggle/working/train'\ntrain_generator = create_generator(DIR=Train_Dir)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YroIriCjQbSm","outputId":"69e2f01d-dd6f-442d-c771-4d7c7b37bc32","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Val_Dir = '/kaggle/working/validation'\nvalidation_generator = create_generator(DIR=Val_Dir)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YYKG_aG3RGAJ","outputId":"c72ceedd-7cec-4ac4-daff-d679dedd0db7","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n> For Future Debugging...\n\n","metadata":{"id":"D4QVQhK3RUFQ"}},{"cell_type":"markdown","source":"# Pilot Modeling","metadata":{"id":"FNeYtk3dKCYS"}},{"cell_type":"code","source":"# Function to build the model\ndef build_model():\n    image_size = 224\n    ResNet50_base = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(image_size, image_size, 3))\n    model = ResNet50_base.output\n    model = tf.keras.layers.GlobalAveragePooling2D()(model)\n    model = tf.keras.layers.Dropout(rate=0.4)(model)\n    model = tf.keras.layers.Dense(1, activation='sigmoid')(model)\n    model = tf.keras.models.Model(inputs=ResNet50_base.input, outputs=model)\n    return model","metadata":{"id":"WvNPGmVdH8Wd","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callback to reduce learning rate\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.4,\n                              patience=4,\n                              min_delta=0.0001,\n                              mode='auto',\n                              verbose=1)","metadata":{"id":"dzGuqJrYMGgp","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lists to store specificity and sensitivity\nspecificities = []\nsensitivities = []","metadata":{"id":"WWeLz-LtJFxz","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensure TensorFlow uses the GPU\nphysical_devices = tf.config.list_physical_devices('GPU')\nif len(physical_devices) > 0:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n\n# Train the model 6 times\nfor i in range(6):\n    model = build_model()\n    opt = Adam(learning_rate=0.001)\n    model.compile(loss='binary_crossentropy',\n                  optimizer=opt,\n                  metrics=['accuracy', 'Recall', 'Precision'])\n\n    Train_Dir = '/kaggle/working/train'\n    train_gen = create_generator(DIR=Train_Dir)\n    Val_Dir = '/kaggle/working/validation'\n    val_gen = create_generator(DIR=Val_Dir)\n\n    csv_logger = CSVLogger(f'/kaggle/working/model_version_{i+1}_log.csv',\n                           append=True,\n                           separator=',')\n\n    history = model.fit(\n        train_gen,\n        steps_per_epoch= (tr+tr_)//batch_size,\n        epochs=EPOCHS,\n        verbose=1,\n        validation_data=val_gen,\n        callbacks=[reduce_lr, csv_logger]\n    )\n\n    test_path = \"/kaggle/working/test\"\n    test_gen = create_generator(DIR=test_path)\n\n    predictions = model.predict(test_gen, verbose=1)\n    labels = test_gen.classes\n\n    new_list = [0 if value <= 0.50 else 1 for value in predictions]\n    cm = confusion_matrix(labels, new_list)\n\n    tn, fp, fn, tp = cm.ravel()\n    specificity = tn / (tn + fp)\n    sensitivity = tp / (tp + fn)\n\n    specificities.append(specificity)\n    sensitivities.append(sensitivity)\n\n    model.save_weights(f'/kaggle/working/model_version_{i+1}.weights.h5')\n\n    del model\n    del history\n    tf.keras.backend.clear_session()\n\nprint(\"Specificities: \", specificities)\nprint(\"Sensitivities: \", sensitivities)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"PzmJumiKRWyD","outputId":"ada06721-3e1e-4ba7-e0c4-2e9f8213275f","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Box plot for specificity and sensitivity\nplt.figure(figsize=(10, 5))\nplt.boxplot([specificities, sensitivities], labels=['Specificity', 'Sensitivity'])\nplt.title('Specificity and Sensitivity across 6 Runs')\nplt.ylabel('Scores')\nplt.show()\n\n# Plot ROC Curve\nfpr, tpr, _ = roc_curve(labels, predictions)\nroc_auc = auc(fpr, tpr)\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Plot ROC Curve using Specificity and Sensitivity\nplt.figure()\nplt.plot(1 - np.array(specificities), sensitivities, marker='o', linestyle='-', color='darkorange', lw=2, label='ROC curve')\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('1 - Specificity')\nplt.ylabel('Sensitivity')\nplt.title('Receiver Operating Characteristic using Specificity and Sensitivity')\nplt.legend(loc=\"lower right\")\nplt.show()","metadata":{"id":"lV2RSmpNJloV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot model performance\nacc = history.history['recall']\nval_acc = history.history['val_recall']\nloss = history.history['precision']\nval_loss = history.history['val_precision']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(11,4))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('recall')\nplt.title('Model recall')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Precision')\nplt.title('Model Precision')\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"VdvaQSCELliT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(11,4))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","metadata":{"id":"bK7X5EyzSCwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accuracy and loss plots\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(14, 6))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Train Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"id":"qbdQBlj_GrWa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing","metadata":{"id":"ut6ZVSP6Gb4F"}},{"cell_type":"code","source":"test_path = \"/kaggle/working/test\"\ntest_generator = create_generator(test_path)","metadata":{"id":"e2D0x_5GGbIT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_generator)","metadata":{"id":"K3YkybaFGbVE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n> ### Test Report\n\nPrecision = 0.76\n\nRecall = 0.71\n\nAccuracy = 0.74\n\n","metadata":{"id":"mnak5rjZefcV"}},{"cell_type":"markdown","source":"# These lines are just for experimenting","metadata":{}},{"cell_type":"code","source":"# from PIL import Image\n\n# root = \"/content/SkinCancerDataset/data/test\"\n# predictions = []\n# labels = []\n\n# for label in tqdm(os.listdir(root)):\n#   if label == \"malignant\":\n#     new_root = os.path.join(root, label)\n#     for image in tqdm(os.listdir(new_root)):\n#       # read, covert, and normalize the image\n#       img_path = os.path.join(new_root, image)\n#       image_file = Image.open(img_path).convert('RGB')\n#       image_array = np.array(image_file)\n#       # image_array = image_array * 255.0/image_array.max()\n#       image_array = cv2.resize(image_array, (224,224))\n#       image_array = image_array / 255.0\n#       image_array = image_array.reshape(1, 224,224, 3)\n#       # Prediction\n#       predictions.append(model.predict(image_array, verbose=0).squeeze())\n#       labels.append(1)\n\n\n#   elif label == \"benign\":\n#     new_root = os.path.join(root, label)\n#     for image in tqdm(os.listdir(new_root)):\n#       # read, covert, and normalize the image\n#       img_path = os.path.join(new_root, image)\n#       image_file = Image.open(img_path).convert('RGB')\n#       image_array = np.array(image_file)\n#       # image_array = image_array * 255.0/image_array.max()\n#       image_array = cv2.resize(image_array, (224,224))\n#       image_array = image_array / 255.0\n#       image_array = image_array.reshape(1, 224,224, 3)\n#       # Prediction\n#       predictions.append(model.predict(image_array, verbose=0).squeeze())\n#       labels.append(0)\n\n#   else:\n#     print(\"\\nSomething is not right!\")\n\n\n","metadata":{"id":"A8ZbjJCZRVUT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new_list = [0 if value <= 0.50 else 1 for value in predictions]","metadata":{"id":"aCoejECfaJ7L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from sklearn.metrics import confusion_matrix, classification_report\n# import warnings\n# warnings.filterwarnings('ignore')\n\n# confusion_matrix(labels, new_list)","metadata":{"id":"pi-4lk7KfeA4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sns.heatmap(confusion_matrix(labels, new_list), annot=True, cmap=\"Blues\")","metadata":{"id":"PLnFGq1ufKe-"},"execution_count":null,"outputs":[]}]}