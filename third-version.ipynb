{"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"collapsed_sections":["ut6ZVSP6Gb4F","peZaBR-_nhCl"],"include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8564242,"sourceType":"datasetVersion","datasetId":5119916}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Requirements","metadata":{"id":"by1o5v5UDBtj"}},{"cell_type":"code","source":"import cv2\nimport shutil\nimport random\nimport zipfile\nimport warnings\nfrom PIL import Image\nimport numpy as np\n# %load_ext cudf.pandas\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import load_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.applications.resnet import ResNet50\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom tensorflow.keras.callbacks import CSVLogger\n\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'","metadata":{"id":"TWChDwKVCjJ7","outputId":"c778b8b1-4ec2-4e72-e0ad-d304d40f225e","execution":{"iopub.status.busy":"2024-06-14T16:17:15.702459Z","iopub.execute_input":"2024-06-14T16:17:15.702860Z","iopub.status.idle":"2024-06-14T16:17:15.712698Z","shell.execute_reply.started":"2024-06-14T16:17:15.702831Z","shell.execute_reply":"2024-06-14T16:17:15.711263Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"benigns = len(os.listdir(\"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/benign\"))\nmelignant = len(os.listdir(\"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/malignant\"))\nprint(f\"Number of benign Samples: {benigns}\\nNumber of malignant Samples: {melignant}\")","metadata":{"id":"ASydytmeE3lj","outputId":"c7f5e8dc-7f75-4650-ef71-345b764d446a","execution":{"iopub.status.busy":"2024-06-14T15:01:36.732279Z","iopub.execute_input":"2024-06-14T15:01:36.733011Z","iopub.status.idle":"2024-06-14T15:01:43.547851Z","shell.execute_reply.started":"2024-06-14T15:01:36.732976Z","shell.execute_reply":"2024-06-14T15:01:43.546659Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Number of benign Samples: 584\nNumber of malignant Samples: 584\n","output_type":"stream"}]},{"cell_type":"code","source":"# Balance the dataset by removing excess samples from the majority class\nfrom random import sample\nmin_path = \"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/malignant\"\nmaj_path = \"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/benign\"\naddress = [image for image in os.listdir(maj_path)]\ncut = len(os.listdir(min_path))\ncut_list = sample(address, cut)\nfor index in tqdm(os.listdir(maj_path)):\n    if index not in cut_list:\n        os.remove(os.path.join(maj_path, index))\n\n# Verify the number of samples\nbenigns = len(os.listdir(\"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/benign\"))\nmelignant = len(os.listdir(\"/kaggle/input/skin-canser-b584m584/Melanoma-b584m584/malignant\"))\nprint(f\"\\nNumber of benign Samples: {benigns}\\nNumber of malignant Samples: {melignant}\")","metadata":{"id":"WERv5Wrohmmf","outputId":"645d09b5-1a66-4f09-d701-db05ebb0270f","execution":{"iopub.status.busy":"2024-06-14T15:01:43.549884Z","iopub.execute_input":"2024-06-14T15:01:43.550555Z","iopub.status.idle":"2024-06-14T15:01:43.574823Z","shell.execute_reply.started":"2024-06-14T15:01:43.550523Z","shell.execute_reply":"2024-06-14T15:01:43.573779Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"100%|██████████| 584/584 [00:00<00:00, 71697.50it/s]","output_type":"stream"},{"name":"stdout","text":"\nNumber of benign Samples: 584\nNumber of malignant Samples: 584\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Here since the path to dataset is read-only we need to copy them to another Dir\nnew_path = '/kaggle/working/train'\nos.makedirs(new_path, exist_ok=True)\nshutil.copytree('/kaggle/input/skin-canser-b584m584/Melanoma-b584m584', new_path, dirs_exist_ok=True)\n# Just to Verify\nprint(os.listdir(new_path))","metadata":{"execution":{"iopub.status.busy":"2024-06-14T15:01:46.633919Z","iopub.execute_input":"2024-06-14T15:01:46.634312Z","iopub.status.idle":"2024-06-14T15:02:00.044678Z","shell.execute_reply.started":"2024-06-14T15:01:46.634284Z","shell.execute_reply":"2024-06-14T15:02:00.043586Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"['malignant', 'b584m584.csv', 'benign']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to divide a test set\ndef divide_test_set(temp_path, cut_percentage):\n    \"\"\"\n    Returns a list containing relative address for images you need to move\n    ------------------------------------------------------------------------\n    temp_path: \n                    a path to the root directory of your data\n    \n    cut_precentage: \n                    how much data you want to move\"\"\"\n    \n    rel_image_paths = [os.path.join(temp_path, i) for i in os.listdir(temp_path)]\n    cut_set = random.sample(rel_image_paths, int(cut_percentage * len(os.listdir(temp_path))))\n    return cut_set","metadata":{"execution":{"iopub.status.busy":"2024-06-14T15:01:43.576121Z","iopub.execute_input":"2024-06-14T15:01:43.576454Z","iopub.status.idle":"2024-06-14T15:01:43.582431Z","shell.execute_reply.started":"2024-06-14T15:01:43.576426Z","shell.execute_reply":"2024-06-14T15:01:43.581257Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def copy_data(input_list, path):\n    \"\"\"Copies all the data located at the input list indexes\n    -------------------------------------------------------------\n    input_list: \n                a list containing all the relative paths\n    \n    path:\n                output directory\"\"\"\n    \n    os.makedirs(path, exist_ok=True)\n    for index in (input_list):\n        shutil.copy(index, path) # Changed from \"move\" to \"copy\" and also merged 3 redundent scripts into a func","metadata":{"id":"FA7qjcoimOXj","execution":{"iopub.status.busy":"2024-06-14T16:04:03.137115Z","iopub.execute_input":"2024-06-14T16:04:03.137870Z","iopub.status.idle":"2024-06-14T16:04:03.144088Z","shell.execute_reply.started":"2024-06-14T16:04:03.137836Z","shell.execute_reply":"2024-06-14T16:04:03.142801Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Data generator for training, validation and testing\ndef create_generator(DIR):\n    datagen = ImageDataGenerator(rescale=1/255)\n    generator = datagen.flow_from_directory(directory=DIR,\n                                            batch_size=batch_size,\n                                            class_mode='binary',\n                                            target_size=(224, 224))\n    return generator","metadata":{"id":"Xteh2dlNMGjK","execution":{"iopub.status.busy":"2024-06-14T15:08:00.910823Z","iopub.execute_input":"2024-06-14T15:08:00.911279Z","iopub.status.idle":"2024-06-14T15:08:00.917778Z","shell.execute_reply.started":"2024-06-14T15:08:00.911246Z","shell.execute_reply":"2024-06-14T15:08:00.916626Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def test_me(root):\n    \"\"\"\n    This function captures prediction/label pairs and return predictions, labels lists\n    ------------------------------------------------\n    root: \n            a relative path to the test directory\"\"\"\n    predictions = []\n    labels = []\n    for label in tqdm(os.listdir(root)):\n        if label == \"malignant\":\n            new_root = os.path.join(root, label)\n            for image in tqdm(os.listdir(new_root)):\n                # read, covert, and normalize the image\n                img_path = os.path.join(new_root, image)\n                image_file = Image.open(img_path).convert('RGB')\n                image_array = np.array(image_file)\n                # image_array = image_array * 255.0/image_array.max()\n                image_array = cv2.resize(image_array, (224,224))\n                image_array = image_array / 255.0\n                image_array = image_array.reshape(1, 224,224, 3)\n                # Prediction\n                predictions.append(model.predict(image_array, verbose=0).squeeze())\n                labels.append(1)\n                \n            return predictions, labels \n\n\n        elif label == \"benign\":\n            new_root = os.path.join(root, label)\n            for image in tqdm(os.listdir(new_root)):\n                # read, covert, and normalize the image\n                img_path = os.path.join(new_root, image)\n                image_file = Image.open(img_path).convert('RGB')\n                image_array = np.array(image_file)\n                # image_array = image_array * 255.0/image_array.max()\n                image_array = cv2.resize(image_array, (224,224))\n                image_array = image_array / 255.0\n                image_array = image_array.reshape(1, 224,224, 3)\n                # Prediction\n                predictions.append(model.predict(image_array, verbose=0).squeeze())\n                labels.append(0)\n            \n            return predictions, labels \n\n        else:\n            return \"\\nSomething is not right!\"","metadata":{"execution":{"iopub.status.busy":"2024-06-14T16:21:45.597281Z","iopub.execute_input":"2024-06-14T16:21:45.597692Z","iopub.status.idle":"2024-06-14T16:21:45.612095Z","shell.execute_reply.started":"2024-06-14T16:21:45.597658Z","shell.execute_reply":"2024-06-14T16:21:45.610871Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Function to build the model\ndef build_model():\n    image_size = 224\n    ResNet50_base = ResNet50(weights=\"imagenet\", include_top=False, input_shape=(image_size, image_size, 3))\n    model = ResNet50_base.output\n    model = tf.keras.layers.GlobalAveragePooling2D()(model)\n    model = tf.keras.layers.Dropout(rate=0.4)(model)\n    model = tf.keras.layers.Dense(1, activation='sigmoid')(model)\n    model = tf.keras.models.Model(inputs=ResNet50_base.input, outputs=model)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-14T15:23:08.611129Z","iopub.execute_input":"2024-06-14T15:23:08.611603Z","iopub.status.idle":"2024-06-14T15:23:08.619549Z","shell.execute_reply.started":"2024-06-14T15:23:08.611569Z","shell.execute_reply":"2024-06-14T15:23:08.618165Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Training parameters\nbatch_size = 4\nEPOCHS = 40\ntest_accs = []\ntest_recalls = []\ntest_precisions = []\ntps = []\nfps = []\ntns = []\nfns = []\n\n\n# Ensure TensorFlow uses the GPU\nphysical_devices = tf.config.list_physical_devices('GPU')\nif len(physical_devices) > 0:\n    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n\n\nfor i in tqdm(range(6)):\n    # Divide the dataset into training and test sets\n    input_path = \"/kaggle/working/train/benign\"\n    benign_test_set = divide_test_set(input_path, 0.20)\n    input_path = \"/kaggle/working/train/malignant\"\n    malignant_test_set = divide_test_set(input_path, 0.20)\n    \n    # Move batches of data into correspounding folders\n    copy_data(path = \"/kaggle/working/test/benign\")\n    copy_data(path = \"/kaggle/working/test/malignant\")\n    \n    # Create train and validation directories\n    train_benign_dir = \"/kaggle/working/train/benign\"\n    train_malignant_dir = \"/kaggle/working/train/malignant\"\n    validation_dir = \"/kaggle/working/validation\"\n    os.makedirs(validation_dir, exist_ok=True)\n    validation_benign_dir = os.path.join(validation_dir, \"benign\")\n    validation_malignant_dir = os.path.join(validation_dir, \"malignant\")\n    os.makedirs(validation_benign_dir, exist_ok=True)\n    os.makedirs(validation_malignant_dir, exist_ok=True)\n    \n    # Data Splitting\n    split_percent = 0.20\n#     shuffle_and_split_data(train_benign_dir, validation_benign_dir, split_percent)\n#     shuffle_and_split_data(train_malignant_dir, validation_malignant_dir, split_percent)\n    \"\"\"Need to modify this and use new functions ....\"\"\"\n\n    print(f\"\\n{i} out of 6 Dataset splitted.\")\n    \n    # Used for Fit() and Verification of Splitting ...\n    va = len(os.listdir(\"/kaggle/working/validation/benign\"))\n    tr = len(os.listdir(\"/kaggle/working/train/benign\"))\n    va_ = len(os.listdir(\"/kaggle/working/validation/malignant\"))\n    tr_ = len(os.listdir(\"/kaggle/working/train/malignant\"))\n    print(f\"\\nNumber of benign train Samples: {tr}\\nNumber of benign validation Samples: {va}\")\n    print(f\"\\nNumber of malignant train Samples: {tr_}\\nNumber of malignant validation Samples: {va_}\")\n    \n    # Create data generators\n    Train_Dir = '/kaggle/working/train'\n    train_generator = create_generator(DIR=Train_Dir)\n    Val_Dir = '/kaggle/working/validation'\n    validation_generator = create_generator(DIR=Val_Dir)\n    \n    # Build a model and pick an optimizer\n    model = build_model()\n    opt = Adam(learning_rate=0.001)\n    \n    # Callback and Logger\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=4, min_delta=0.0001, mode='auto', verbose=1)\n    csv_logger = CSVLogger(f'/kaggle/working/model_version_{i+1}_log.csv', append=True, separator=',')\n    \n    # Compile and Run\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy', 'Recall', 'Precision'])\n    history = model.fit(\n        train_gen,\n        steps_per_epoch= (tr+tr_)//batch_size,\n        epochs=EPOCHS,\n        verbose=1,\n        validation_data=val_gen,\n        callbacks=[reduce_lr, csv_logger]\n    )\n    \n    model.save_weights(f'/kaggle/working/model_version_{i+1}.weights.h5')\n    \n    # Testing begins here ...\n    test_path = \"/kaggle/working/test\"\n    test_gen = create_generator(DIR=test_path)\n    \n    # Capture common metrics\n    c_metrics = model.evaluate(test_generator)\n    test_accs.append(c_metrics[1])\n    test_recalls.append(c_metrics[2])\n    test_precisions.append(c_metrics[3])\n    \n    # Make predictions\n    predictions, labels = test_me(test_path)\n    new_list = [0 if value <= 0.50 else 1 for value in predictions]\n    \n    cf = confusion_matrix(labels, new_list)\n    tn = confusion_matrix[0, 0]  # True Negatives\n    fp = confusion_matrix[0, 1]  # False Positives\n    fn = confusion_matrix[1, 0]  # False Negatives\n    tp = confusion_matrix[1, 1]  # True Positives\n\n    # Just logging everything\n    print(f\"\\n{i}/6 model performance:\\nTN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\")\n    tns.append(tn)\n    fps.append(fp)\n    fns.append(fn)\n    tps.append(tp)\n    print(\"=\"*100)\n    \n    # Clear the path for the next training index\n    shutil.rmtree(\"/kaggle/working/test\")\n    shutil.rmtree(\"/kaggle/working/validation\")\n    del model\n    del history\n    tf.keras.backend.clear_session()\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-14T15:02:37.167084Z","iopub.execute_input":"2024-06-14T15:02:37.167511Z","iopub.status.idle":"2024-06-14T15:02:37.176913Z","shell.execute_reply.started":"2024-06-14T15:02:37.167478Z","shell.execute_reply":"2024-06-14T15:02:37.175913Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 6/6 [00:00<00:00, 18669.01it/s]","output_type":"stream"},{"name":"stdout","text":"Hi\nHi\nHi\nHi\nHi\nHi\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}